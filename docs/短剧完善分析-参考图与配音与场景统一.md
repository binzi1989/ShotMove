# 短剧完善分析：参考图、场景统一、配音

## 已实现改动（按本文改法落地）

- **分镜角色名**：LLM 分镜格式改为 11 列，新增「本镜主要角色名」列；解析后写入 `character_name`；对白列支持从「角色名：」解析兜底。模板分镜同样输出 `character_name`。
- **按镜配音**：主流程 `/api/video` 在短剧+配音时使用 `concat_video_segments_with_durations` / `single_segment_to_merged_with_duration` 拿到 `segment_durations`，并传入 `_add_bgm_and_voiceover(storyboard=..., segment_durations=...)`，走按镜 TTS，配音与画面对齐。
- **情景统一**：短剧每镜 prompt 前加全局风格前缀（`SCRIPT_DRAMA_STYLE_PREFIX`，默认「电影感、自然光、色调统一。」）；分镜 LLM 要求「所有镜头的风格、光线、色调保持一致」。
- **参考图与配置**：`.env.example` 与 `_save_character_refs_and_build_urls` 注释中明确：可灵需公网 URL，未配置 `BACKEND_PUBLIC_URL` 时角色参考图不会传给可灵。

---

## 一、你提到的三个问题

1. **上传的主角/配角参考图没有用上**
2. **生成的视频情景没有统一**
3. **配音对不上，且用的是 MiniMax TTS**

下面按「现状 → 根因 → 改法」说明，最后给出**在现有项目上改 vs 重启新项目**的结论。

---

## 二、问题 1：参考图没有用上

### 现状

- 前端可以传 `character_references`（主角/配角 + name + image_base64）。
- 后端会保存到 `static/merged/character_refs/{job_id}/ref_{i}.jpg`，并拼出 URL 传给视频生成。
- 可灵短剧在 `_run_script_drama_kling` 里按镜解析「该镜用哪张参考图」：优先按分镜的 `character_name` 匹配角色名，没有则用「第一个主角」「第一个配角」。

### 根因（为什么你看到「没用到」）

1. **参考图 URL 必须是公网可访问**  
   可灵从他们的服务器拉图，只能拉 `http(s)://...`。  
   当前 URL 形如：`{BACKEND_PUBLIC_URL}/api/character-refs/{job_id}/ref_{i}.jpg`。  
   若 **未配置 `BACKEND_PUBLIC_URL`**（或配置成内网地址），则生成时用的是相对路径 `/api/...`，代码里会判断「不是 http(s)」从而 **不把参考图塞进 image_list**，等价于没传图。
2. **分镜里没有「角色名」**  
   分镜表来自 LLM，当前 prompt 只有 10 列，**没有「角色名」这一列**，所以每条分镜的 `character_name` 一直是空。  
   后端会 fallback 到「第一个主角」：所有镜头都会用同一张主角图；**配角图**在「先主角后配角」的 fallback 下通常用不上（除非没有主角图才会用到第一个配角）。
3. **前端传的 name 和分镜对不上**  
   即使用户上传了「李华」「小明」，分镜里没有 `character_name`，也匹配不到，只能整片用一张 fallback 图。

### 改法（在现有代码上就能做）

- **必须**：配置 `BACKEND_PUBLIC_URL` 为公网可访问的 backend 地址（如 `https://your-domain.com`），保证 `/api/character-refs/...` 可被可灵访问。
- **推荐**：  
  - 分镜增加「角色名」：在 LLM 生成分镜的格式里加一列「本镜主要角色名」，解析后写入 `StoryboardItem.character_name`；或从对白列用简单规则解析「李华：xxx」→ 李华。  
  - 前端上传角色时填的 `name` 与剧本里角色名一致，这样按镜才能匹配到对应参考图。
- 可选：无 `character_name` 时，多角色场景可以按「本镜对白来自哪个角色」推断用哪张参考图（需要一点启发式或 LLM 标注）。

结论：**参考图逻辑已经存在，主要是「公网 URL + 分镜角色名」没打通，在现有项目里修即可。**

---

## 三、问题 2：情景没有统一

### 现状

- 每镜独立调可灵：每镜一个 prompt，没有全局风格/场景/色调约束，也没有 seed 传递。
- 所以光线、色调、场景质感容易镜与镜之间不一致。

### 根因

- 没有「全局视觉设定」注入到每镜的 prompt；
- 可灵是否支持 seed 未在现有代码里使用，风格完全靠每镜描述，容易漂移。

### 改法（在现有代码上就能做）

- **统一风格描述**：在 `_shot_prompt` 或调用可灵前，给短剧加一个「全局风格前缀/后缀」（如「整片：现代都市、冷色调、电影感、自然光」），每镜 prompt 都带上，减少风格漂移。
- **分镜阶段就约束**：在 LLM 生成分镜的 system 里要求「所有镜头的风格、光线、色调保持一致，与剧本时代/场景统一」。
- 若可灵 API 支持 **seed**：同一短剧所有镜用同一 seed，有利于一致性（需查可灵文档并接入）。

结论：**属于「补一层风格约束 + 可选 seed」的迭代，不需要重写项目。**

---

## 四、问题 3：配音对不上 + TTS 引擎

### 现状

- **按镜配音**的完整逻辑已经存在：`_add_bgm_and_voiceover` 里当 `pipeline == "script_drama"` 且传入 **storyboard + segment_durations** 时，会按镜取 `copy_text` 做 TTS，无台词镜用静音，再用 `build_voice_track_from_segments` 按每段时长裁切/拼接，这样配音和画面是对齐的。
- 但在 **主流程** `/api/video`（generate_video）里，短剧成片后调用 `_add_bgm_and_voiceover` 时**没有传 storyboard 和 segment_durations**，只传了 `script_text = req.script_summary`，于是走了「整段 script 一次性 TTS」的分支，再整段混进成片，**和每镜时长、每镜台词完全对不上**。
- 只有「先分段再拼接」的接口 `/api/video/concat-from-segments` 传了 storyboard + segment_durations，所以那一支是按镜配音、能对上的。

### 根因

- 主流程没有在合并后计算各段时长（segment_durations），也没有把 storyboard 和 segment_durations 传给 `_add_bgm_and_voiceover`，导致短剧在主流程里永远用「整段 TTS」，所以对不上。

### 改法（在现有代码上就能做）

- 在 `generate_video` 里，**短剧**且 **with_voiceover** 且合并出 `merged_url` 后：  
  - 用已有分段文件（或从 download_urls 下载后的本地路径）用 ffprobe 得到每段时长，得到 `segment_durations`；  
  - 调用 `_add_bgm_and_voiceover(..., storyboard=req.storyboard, segment_durations=segment_durations)`。  
- 这样就会走现有的「按镜 TTS + 按段裁切/静音 + 拼接」逻辑，配音和镜头一一对应。

关于 **TTS 引擎**：当前代码里 `main.py` 用的是 **讯飞超拟人**（`iflytek_speech.text_to_speech`），不是 MiniMax。若你实际听到的是 MiniMax，可能是环境/配置或别的入口。若希望统一或换成 MiniMax/其他引擎，只需在 main 里改 `text_to_speech` 的导入与调用（以及对应的 voice_id 推断），无需动整体架构。

结论：**配音对不上的根因是主流程没传「按镜」所需的 storyboard + segment_durations；补上即可用现有按镜配音逻辑。TTS 引擎可插拔替换。**

---

## 五、在现有基础上改 vs 重启新项目

### 现有项目里已经有的

- 分镜数据结构（StoryboardItem、character_name、copy_text、t2v_prompt 等）
- 可灵调用（omni / 文生）、按镜生成、不并发不限时
- 角色参考图的保存、URL 构建、按镜解析（_resolve_shot_character_url、主角/配角 fallback）
- 按镜配音的完整实现（build_voice_track_from_segments、按镜 TTS + 静音 + 时长裁切）
- 合并、转场、字幕、后期流程
- 讯飞 TTS 对接（以及可替换为 MiniMax 的接口形态）

### 还缺的 / 要修的

| 点           | 类型     | 工作量 |
|--------------|----------|--------|
| BACKEND_PUBLIC_URL 配置 + 参考图公网可访问 | 配置/部署 | 小 |
| 分镜带 character_name（LLM 多一列或从对白解析） | 后端 + prompt | 小～中 |
| 短剧主流程传 storyboard + segment_durations 做按镜配音 | 后端一处调用 | 小 |
| 全局风格/统一情景（风格前缀 + 可选 seed） | 后端 + 可灵参数 | 小～中 |
| 更换 TTS 引擎（若要用 MiniMax） | 替换实现/配置 | 小 |

以上都是**在现有架构上补全、修正**，没有需要推倒重来的部分。

### 结论

- **建议在现有项目上迭代，不要重启新项目。**
  - 参考图、按镜配音、可灵调用、合并与字幕的链路都已经存在，只是「参考图公网 URL」「分镜角色名」「主流程传 segment_durations + storyboard」没接好，以及风格未统一。
  - 修这些点的改动面清晰、工作量可控；重启一个新项目会重新实现一遍分镜、可灵、合并、TTS、字幕，成本高且容易重复踩坑。
- 若你希望「短剧」和「短视频」在代码上更隔离，可以在现有仓库里用「短剧专用模块/路由」做一层封装，而不是另起一个项目。

---

## 六、建议的落地顺序

1. **先打通参考图**：配置 `BACKEND_PUBLIC_URL`，确认可灵能拉到图；分镜增加或解析出 `character_name`，保证主角/配角图按镜用上。
2. **再修配音对齐**：在 `generate_video` 里为短剧计算并传入 `segment_durations` + `storyboard`，走按镜 TTS。
3. **最后做情景统一**：全局风格前缀 + 分镜 prompt 约束 + 可选 seed。

这样你可以先看到「参考图生效 + 配音对上」，再优化观感一致性。
